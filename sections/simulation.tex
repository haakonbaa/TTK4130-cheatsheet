\section{Simulation methods}

\textbf{Butcher tableau}
\begin{align*}
\begin{array}{c|c}
    \bm{c} & A  \\ \hline
     & \bm{b}^T
\end{array}
\end{align*}
\begin{align*}
    K_n &= f(t_k+\Delta t c_n,x_n + \Delta t (A_n)K) \\
    x_{k+1} &= x_k + \Delta t\bm{b}^TK
\end{align*}
The method is \textbf{consistent} if
\begin{align*}
    c_n &= \Sigma_{i}A_{ni} \\
    \Sigma_i \bm{b}_i &= 1
\end{align*}
The \textbf{stages} of a Runge Kutta method is the number of elements in \(\bm{c}\).
The Butcher Tableu defines an explicit integrator if and only if the diagonal
elements and the upper-diagonal elements are zero.
\newline

\textbf{Stability function}
For the Butcher Tableu
\begin{align*}
\begin{array}{c|c}
    \bm{c} & \bm{A}  \\ \hline
     & \bm{b}^T
\end{array}
\end{align*}
The stability function is
\begin{align*}
    R(z) = \frac{\det|\mathbb{I}-z(\bm{A}-\bm{1}\bm{b}^T)|}{\det|\mathbb{I}-z\bm{A}|}
\end{align*}

\textbf{Explicit Euler}
\begin{align*}
    &\bm{x}_{k+1} = \bm{x}_k + \Delta t \cdot \bm{f}(\bm{x},\bm{u}) 
    &\begin{array}{c|c}
         0 & 0 \\ \hline
          & 1
    \end{array}
\end{align*}
Global error \(||\bm{x}_N-\bm{x}(T)|| = \mathcal{O}(\Delta t)\)
\newline
Stability function \(R(z) = 1+z\)
\newline

\textbf{Explicit mid-point rule}
\begin{align*}
\begin{array}{c|cc}
    0 & 0 & 0 \\
    1/2 & 1/2 & 0 \\ \hline
     & 0 & 1/2
\end{array}
\end{align*}
Global error \(||\bm{x}_N-\bm{x}(T)|| = \mathcal{O}(\Delta t^2)\)
\newline

\textbf{Ralston's RK2}
\begin{align*}
\begin{array}{c|cc}
    0 & 0 & 0 \\
    2/3 & 2/3 & 0 \\ \hline
     & 1/4 & 1/3
\end{array}
\end{align*}

\textbf{Heun's RK2}
\begin{align*}
\begin{array}{c|cc}
    0 & 0 & 0 \\
    1 & 1 & 0 \\ \hline
     & 1/2 & 1/2
\end{array}
\end{align*}

\textbf{Generic second-order method}
\begin{align*}
\begin{array}{c|cc}
    0 & 0 & 0 \\
    \alpha & \alpha & 0 \\ \hline
     & 1-\frac{1}{2\alpha} & \frac{1}{2\alpha}
\end{array}
\end{align*}

\textbf{Generic third-order method}
\begin{align*}
\begin{array}{c|ccc}
    0 & 0 & 0 & 0\\
    \alpha & \alpha & 0 & 0\\
    1 & 1+\frac{1-\alpha}{\alpha(3\alpha-2)} & -\frac{1-\alpha}{\alpha(3\alpha-2)} & 0 \\ \hline
     & \frac{1}{2}-\frac{1}{6\alpha} & \frac{1}{6\alpha(1-\alpha)} & \frac{2-3\alpha}{6(1-\alpha)} 
\end{array}
\end{align*}


\textbf{"The" RK4 method}
\begin{align*}
\begin{array}{c|cccc}
    0 & 0 & 0 & 0 & 0\\
    1/2 & 1/2 & 0 & 0 & 0\\
    1/2 & 0 & 1/2 & 0 & 0\\
    1 & 0 & 0 & 1 & 0 \\ \hline
     & 1/6 & 1/3 & 1/3 & 1/6
\end{array}
\end{align*}
Global error \(||\bm{x}_N-\bm{x}(T)|| = \mathcal{O}(\Delta t^4)\)
\newline

\textbf{One-Step error}
\begin{align*}
    ||\bm{x}_{k+1}-\bm{x}(t_{k+1})||
\end{align*}
Taylor expand \(\bm{x}(t)\) around \(t_k\). Do the same for \(\bm{x}_{k+1}\). Subtract and get the results
\newline

\textbf{Global error}
Get error on time step \(T\) by multiplying local error with \(N=\frac{T}{\Delta t}\)
\newline

\textbf{stability of integration method}: Consider the ODE
\begin{align*}
    \dot{x}&=\lambda x & x(0) &= x_0
\end{align*}
Perform one step of the RK method to find
\begin{align*}
    x_{n+1} &= R(z)x_n & z &= \Delta t \lambda
\end{align*}
The integration method is unstable if
\begin{align*}
    |R(z)| > 1
\end{align*}

\textbf{A-stability}
A method is A-stable if the region of stability is the entire left-half plane.
\begin{align*}
    |R(\lambda\Delta t)|\leq 1 \forall \lambda \in \CC \textrm{ s.t. } \mathcal{R}(\lambda) \leq 0
\end{align*}

\textbf{L-stability}.
A Runge Kutta method is L-stable if it is A-stable and
\[\lim_{\omega \rightarrow \pm \infty}|R(i\omega h)|= 0\]

\textbf{Implicit methods}
\begin{itemize}
    \item Can achieve high and systematic orders
    \item Can be stable regardless of the step size 
    \item Can handle the simulation of DAEs (must be index 1)
    \item Can give huge speed-up when system is stiff
    \item Can achieve order \(o=2s\) for any stage \(s\). Explicit methods can only achieve \(o=s\) and only for \(s\leq4\)
\end{itemize}

\textbf{Implicit Euler}
\begin{align*}
\begin{array}{c|cc}
    1 & 1\\ \hline
     & 1
\end{array}
\end{align*}
\begin{align*}
    k_1 &= f(x_n + \Delta t k_1) \\
    x_{n+1} &= x_n + \Delta t k_1 \\
    &= x_n + \Delta t f(x_{n+1})
\end{align*}

\textbf{Trapezoidal method}
\begin{align*}
\begin{array}{c|cc}
    0 & 0 & 0 \\
    1  & 1/2 & 1/2 \\ \hline
     & 1/2 & 1/2
\end{array}
\end{align*}

\textbf{Gauss-Legendre collocation method}
Generates order \(o=2s\) A-stable IRK methods. Let \(s\) be the number of stages. Find the roots \((\tau_i)\) of 
\[P_s(\tau)=\frac{1}{s!}\frac{d^s}{d\tau^s}\left((\tau^2-\tau)^s\right)\]
Build polynomials
\[\ell_i(\tau) = \prod_{j\neq i}\frac{\tau-\tau_j}{\tau_i-\tau_j}\]
Integrate them
\[L_i(\tau) = \int_0^\tau\ell_i(\xi)\,d\xi\]
Calculate \(A\) ,\(\bm{b}\) and \(\bm{c}\)
\begin{align*}
    A_{ji} &= L_i(\tau_j) & b_i &= L_i(1) & c_j &=  \tau_j
\end{align*}

\textbf{Adaptive integrator}. 
Use two methods: \(x_{n+1}\) and \(\hat{x}_{n+1}\), of different order: \(p\) and \(p+1\). The local error is
\begin{align*}
    \epsilon_{n+1} &:= |x_{n+1}-\hat{x}_{n+1}| \\
    &\approx \mathcal{O}(\Delta t^{p+1})- \mathcal{O}(\Delta t^{p+2}) \\ 
    &\approx C\Delta t^{p+1} \\
    e_{\textrm{tol}} &=  C\Delta t^{p+1}_{\textrm{new}} \Rightarrow \\
    \Delta t_{\textrm{new}} &= \Delta t \left(\frac{e_{\textrm{tol}}}{\epsilon_{n+1}}\right)^{\frac{1}{p+1}}
\end{align*}

\textbf{Newtons method}
\begin{align*}
    \bm{f}(\bm{x}+\Delta \bm{x}) &\approx  \bm{f}(\bm{x}) + \frac{\partial \bm{f}}{\partial \bm{x}}(\bm{x})\Delta \bm{x}  = \bm{0} \\
    \Delta \bm{x} &= - \left(\frac{\partial \bm{f}}{\partial \bm{x}}(\bm{x})\right)^{-1}\bm{f}(\bm{x}) \\
    \bm{x}_{n+1} &= \bm{x}_n + \alpha \Delta \bm{x}
\end{align*}
\begin{itemize}
    \item May not work if jacobian is singular
    \item Has quadratic convergence when it converges
    \item May diverge
\end{itemize}

\textbf{RK method on implicit DAEs/ODEs}
Given the implicit ODE / DAE
\begin{align*}
    \bm{F}(\dot{\bm{x}},\bm{x},\bm{z},\bm{u},t) = \bm{0}
\end{align*}
The \(\bm{K}=(\bm{K}_1,\cdots,\bm{K}_s)^T\) vector / matrix can be found by solving
\begin{align*}
    & \bm{r}(\bm{K},\bm{x}_k,\bm{z},\bm{u}(\cdot),t_k) = \\ 
    & \begin{pmatrix}
        \bm{F(\bm{K}_1,\bm{x}_n+\Delta t\bm{a}_1^T\bm{K},\bm{z}_1,\bm{u}(t_k+\Delta t c_1),t_k+\Delta t c_i)} \\ \vdots \\
        \bm{F(\bm{K}_s,\bm{x}_n+\Delta t\bm{a}_s^T\bm{K},\bm{z}_s,\bm{u}(t_k+\Delta t c_s),t_k+\Delta t c_i)}
    \end{pmatrix} \\ &= \bm{0}
\end{align*}
for \(\bm{K}\) and \(\bm{z}\)
\newline

\textbf{Computational cost of ERK methods}. Let \(T_\textrm{ol}\) be the global tolerance. 
\begin{align*}
    ||\bm{x}_n-\bm{x}(T)|| &\leq c\Delta t^o\leq T_\textrm{ol} \\
    \Delta t &\leq \left(\frac{T_\textrm{ol}}{c}\right)^{(1/o)}
\end{align*}
The number of integrator steps is
\begin{align*}
    N = T/{\Delta t}
\end{align*}
The system dynamics must be evaluated \(s\) times for each integration step
\begin{align*}
    n &= Ns = \frac{sT}{\Delta t} \geq sT\left(\frac{T_\textrm{ol}}{c}\right)^{-1/o} \\
    \frac{n}{T} &\geq s\left(\frac{T_{\textrm{ol}}}{c}\right)^{-1/o}
\end{align*}

\(n\) is the number of function evaluations, \(T\) is the simulation time, \(s\) = \(\#\) stages. \(T_\textrm{ol}\) is the global tolerance and \(o\) is the order. Using the correlation between maximum order and number of stages we get that the optimum order is between 3 and 6.
